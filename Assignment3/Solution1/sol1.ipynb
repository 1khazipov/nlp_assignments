{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def read_jsonl_file(file_path):\n",
    "    \"\"\"\n",
    "    read a JSONL file and return its contents as a list of dictionaries\n",
    "    \"\"\"\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        return [json.loads(line) for line in f]\n",
    "\n",
    "\n",
    "train_data = read_jsonl_file(\"../data/train.jsonl\")\n",
    "dev_data = read_jsonl_file('../data/dev.jsonl')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data processings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Бостон взорвали Тамерлан и Джохар Царнаевы из Северного Кавказа\\n\\n19 апреля 2013 года в пригороде Бостона  проходит спецоперация по поимке 19-летнего Джохара Царнаева, подозреваемого в теракте на Бостонском марафоне 15 апреля и в смертельном ранении полицейского на кампусе Массачусетского технологического института 18 апреля.\\n\\nВторой подозреваемый, его брат, 26-летний Тамерлан Царнаев, был ранен в перестрелке в Уотертауне  и позже скончался в больнице.\\n\\nУотертаун и его окрестности фактически переведены на осадное положение: окрестности оцеплены, дороги перекрыты, магазины и бизнесы закрыты, жителей просят не выходить из домов и не приближаться к окнам, над районом спецоперации перекрыты полёты авиации.\\n\\nВ Бостоне приостановлена работа общественного транспорта, включая метро, автобусы, такси и пригородные поезда. Отменены занятия в Гарварде, Массачусетском технологическом институте, Университете Саффолка, Бостонском университете и во всех городских школах.\\n\\nНа сайте ФБР опубликованы фото и видео разыскиваемого.\\n\\n19-летний студент Университета штата Массачусетс Джохар Царнаев обучался в средней школе Махачкалы, затем в школе Кембриджа (район Бостона), входил в список стипендиатов Кембриджа.\\n\\nСекретарь директора школы №\\xa01 Махачкалы Ирина Бандурина подтвердила «Эху Москвы», что Джохар Царнаев учился в данном учебном заведении, но покинул его, не закончив первый класс.\\n\\nОдин из братьев приехал в США вместе с родителями в 2002 году, а другой — самостоятельно в 2004 году.\\n\\nИнцидент произошел спустя несколько дней после теракта на Бостонском марафоне, во время которого прогремели два взрыва.\\nИх жертвами стали три человека, более 180 получили ранения.\\n',\n",
       " [(0, 6, 'CITY'),\n",
       "  (7, 15, 'EVENT'),\n",
       "  (16, 24, 'PERSON'),\n",
       "  (16, 42, 'FAMILY'),\n",
       "  (27, 42, 'PERSON'),\n",
       "  (34, 42, 'PERSON'),\n",
       "  (46, 63, 'LOCATION'),\n",
       "  (56, 63, 'LOCATION'),\n",
       "  (65, 79, 'DATE'),\n",
       "  (87, 104, 'LOCATION'),\n",
       "  (97, 104, 'CITY'),\n",
       "  (115, 137, 'EVENT'),\n",
       "  (138, 148, 'AGE'),\n",
       "  (149, 165, 'PERSON'),\n",
       "  (184, 191, 'CRIME'),\n",
       "  (195, 205, 'CITY'),\n",
       "  (195, 214, 'EVENT'),\n",
       "  (215, 224, 'DATE'),\n",
       "  (229, 261, 'CRIME'),\n",
       "  (273, 288, 'STATE_OR_PROVINCE'),\n",
       "  (273, 315, 'ORGANIZATION'),\n",
       "  (316, 325, 'DATE'),\n",
       "  (328, 334, 'ORDINAL'),\n",
       "  (360, 369, 'AGE'),\n",
       "  (370, 386, 'PERSON'),\n",
       "  (392, 397, 'EVENT'),\n",
       "  (400, 411, 'EVENT'),\n",
       "  (414, 424, 'CITY'),\n",
       "  (434, 443, 'EVENT'),\n",
       "  (457, 466, 'CITY'),\n",
       "  (714, 721, 'CITY'),\n",
       "  (842, 850, 'ORGANIZATION'),\n",
       "  (852, 866, 'STATE_OR_PROVINCE'),\n",
       "  (852, 892, 'ORGANIZATION'),\n",
       "  (894, 915, 'ORGANIZATION'),\n",
       "  (907, 915, 'CITY'),\n",
       "  (917, 927, 'CITY'),\n",
       "  (917, 940, 'ORGANIZATION'),\n",
       "  (979, 982, 'ORGANIZATION'),\n",
       "  (1026, 1035, 'AGE'),\n",
       "  (1044, 1074, 'ORGANIZATION'),\n",
       "  (1063, 1074, 'STATE_OR_PROVINCE'),\n",
       "  (1075, 1089, 'PERSON'),\n",
       "  (1115, 1124, 'CITY'),\n",
       "  (1140, 1149, 'DISTRICT'),\n",
       "  (1157, 1164, 'CITY'),\n",
       "  (1183, 1195, 'AWARD'),\n",
       "  (1183, 1205, 'AWARD'),\n",
       "  (1196, 1205, 'DISTRICT'),\n",
       "  (1208, 1227, 'PROFESSION'),\n",
       "  (1208, 1247, 'PROFESSION'),\n",
       "  (1228, 1247, 'ORGANIZATION'),\n",
       "  (1238, 1247, 'CITY'),\n",
       "  (1248, 1263, 'PERSON'),\n",
       "  (1277, 1287, 'ORGANIZATION'),\n",
       "  (1294, 1308, 'PERSON'),\n",
       "  (1372, 1378, 'ORDINAL'),\n",
       "  (1413, 1416, 'COUNTRY'),\n",
       "  (1437, 1448, 'DATE'),\n",
       "  (1476, 1487, 'DATE'),\n",
       "  (1537, 1544, 'EVENT'),\n",
       "  (1548, 1558, 'CITY'),\n",
       "  (1548, 1567, 'EVENT'),\n",
       "  (1559, 1567, 'EVENT'),\n",
       "  (1598, 1601, 'NUMBER'),\n",
       "  (1602, 1608, 'EVENT'),\n",
       "  (1613, 1627, 'EVENT'),\n",
       "  (1628, 1631, 'NUMBER'),\n",
       "  (1642, 1651, 'NUMBER'),\n",
       "  (1661, 1668, 'EVENT')])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def process_data(data):\n",
    "    processed_data = []\n",
    "    for entry in data:\n",
    "        sentences = entry['sentences']\n",
    "        ners = sorted(entry['ners'], key=lambda x: x[1] - x[0])\n",
    "        modified_ners = sorted([(entity[0], entity[1] + 1, entity[2]) for entity in ners])\n",
    "        processed_data.append((sentences, modified_ners))\n",
    "    return processed_data\n",
    "\n",
    "prepared_data = process_data(train_data)\n",
    "prepared_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 519/519 [00:02<00:00, 188.74it/s]\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from tqdm import tqdm\n",
    "\n",
    "def convert_dataset(dataset):\n",
    "    converted_dataset = []\n",
    "    for sentence, entities in tqdm(dataset):\n",
    "        tokens = re.findall(r'\\b\\w+\\b', sentence.lower())  # use a regular expression to split into words\n",
    "        tags = ['O'] * len(tokens)  # initialise the tags for each word as an 'O' (not an entity)\n",
    "        for start, end, entity_type in entities:\n",
    "            start_word_index = len(re.findall(r'\\b\\w+\\b', sentence[:start].lower()))  # find the index of the beginning of the word\n",
    "            end_word_index = len(re.findall(r'\\b\\w+\\b', sentence[:end].lower())) - 1  # find the index of the end of the word\n",
    "            if start_word_index == end_word_index:  # if the entity is within the same word\n",
    "                # set tag to B-<entity> for the beginning of the entity\n",
    "                tags[start_word_index] = 'B-' + entity_type\n",
    "            else:\n",
    "                tags[start_word_index] = 'B-' + entity_type\n",
    "                for i in range(start_word_index + 1, end_word_index + 1):\n",
    "                    tags[i] = 'I-' + entity_type # set tag to I-<entity> for the intermediate words\n",
    "        converted_dataset.append((tokens, tags))\n",
    "    return converted_dataset\n",
    "\n",
    "prepared_data = convert_dataset(prepared_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "prepared_data_train, prepared_data_test = train_test_split(prepared_data, train_size=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "prepared_data = {}\n",
    "prepared_data['train'] = prepared_data_train\n",
    "prepared_data['valid'], prepared_data['test'] =  train_test_split(prepared_data_test, test_size=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence 0\n",
      "Tokens: ['первое', 'поражение', 'серены', 'уильямс', 'в', 'финале', 'australian', 'open', 'серена', 'уильямс', '30', 'января', '2016', 'года', 'в', 'финале', 'открытого', 'чемпионата', 'австралии', 'первая', 'ракетка', 'мира', 'американка', 'серена', 'уильямс', 'проиграла', 'немке', 'ангелике', 'кербер', 'со', 'счётом', '6', '4', '3', '6', '6', '4', 'игра', 'шла', 'в', 'течении', 'двух', 'часов', 'и', 'восьми', 'минут', 'это', 'первый', 'турнир', 'большого', 'шлема', 'для', '28', 'летней', 'немки', 'серена', 'до', 'встречи', 'считалась', 'фаворитом', 'финала', 'так', 'как', 'она', 'уже', 'шесть', 'раз', 'проходил', 'в', 'финал', 'турнира', 'и', 'всё', 'время', 'его', 'выигрывала', 'если', 'бы', 'и', 'в', 'этот', 'раз', 'она', 'победила', 'то', 'она', 'бы', 'обновила', 'рекорд', 'за', 'всю', 'открытую', 'эру', 'напомним', 'что', 'открытая', 'эра', 'ведёт', 'отсчёт', 'с', '1968', 'года', 'когда', 'профессионалам', 'разрешили', 'принимать', 'участие', 'в', 'australian', 'open', 'рекордсменом', 'же', 'является', 'маргарет', 'корт', 'в', 'её', 'активе', '11', 'титулов', 'семь', 'раз', 'до', 'открытой', 'эры', 'и', '4', 'раза', 'в', 'ней', 'заметим', 'что', 'кербер', 'первая', 'немка', 'которая', 'выиграла', 'турнир', 'большого', 'шлема', 'в', 'одиночном', 'разряде', 'с', '1999', 'года']\n",
      "Tags:   ['B-ORDINAL', 'O', 'B-PERSON', 'I-PERSON', 'O', 'B-EVENT', 'B-EVENT', 'I-EVENT', 'B-PERSON', 'I-PERSON', 'B-DATE', 'I-DATE', 'I-DATE', 'I-DATE', 'O', 'B-EVENT', 'B-EVENT', 'I-EVENT', 'B-COUNTRY', 'B-AWARD', 'I-AWARD', 'I-AWARD', 'B-NATIONALITY', 'B-PERSON', 'I-PERSON', 'O', 'B-NATIONALITY', 'B-PERSON', 'I-PERSON', 'O', 'O', 'B-NUMBER', 'B-NUMBER', 'B-NUMBER', 'B-NUMBER', 'B-NUMBER', 'B-NUMBER', 'O', 'O', 'B-TIME', 'I-TIME', 'I-TIME', 'I-TIME', 'I-TIME', 'I-TIME', 'I-TIME', 'O', 'B-ORDINAL', 'B-EVENT', 'I-EVENT', 'I-EVENT', 'O', 'B-AGE', 'I-AGE', 'B-NATIONALITY', 'B-PERSON', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-NUMBER', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-DATE', 'I-DATE', 'O', 'O', 'B-DATE', 'I-DATE', 'O', 'O', 'B-DATE', 'I-DATE', 'I-DATE', 'O', 'O', 'O', 'O', 'O', 'O', 'B-EVENT', 'I-EVENT', 'O', 'O', 'O', 'B-PERSON', 'I-PERSON', 'O', 'O', 'O', 'B-NUMBER', 'O', 'B-NUMBER', 'O', 'B-DATE', 'I-DATE', 'I-DATE', 'O', 'B-NUMBER', 'O', 'O', 'O', 'O', 'O', 'B-PERSON', 'B-ORDINAL', 'B-NATIONALITY', 'O', 'O', 'B-EVENT', 'I-EVENT', 'I-EVENT', 'O', 'O', 'O', 'B-DATE', 'I-DATE', 'I-DATE']\n",
      "Sentence 1\n",
      "Tokens: ['заключённый', 'в', 'сизо', 'азат', 'мифтахов', 'написал', 'научную', 'работу', 'по', 'функциональному', 'анализу', 'азат', 'мифтахов', 'на', 'плакате', 'обвиняемый', 'по', 'делу', 'о', 'броске', 'дымовой', 'шашки', 'в', 'офис', 'единой', 'россии', 'аспирант', 'мгу', 'азат', 'мифтахов', 'находящийся', 'сейчас', 'в', 'сизо', 'написал', 'научную', 'работу', 'препринт', 'о', 'барицентрах', 'вероятностных', 'мер', 'выложен', 'на', 'электронный', 'архив', 'научных', 'статей', 'arxiv', 'org', '18', 'ноября', 'работа', 'проделана', 'вместе', 'с', 'математиком', 'сергеем', 'березиным', 'научным', 'сотрудником', 'санкт', 'петербургского', 'отделения', 'математического', 'института', 'лаборатории', 'прикладных', 'вероятностных', 'и', 'алгоритмических', 'методов', 'им', 'в', 'а', 'стеклова', 'ран', 'первая', 'публикация', 'on', 'weak', 'convergence', 'of', 'finite', 'dimensional', 'and', 'infinite', 'dimensional', 'distributions', 'of', 'random', 'processes', 'политического', 'заключённого', 'вышла', 'в', '2016', 'году', 'азата', 'мифтахова', 'задержали', '1', 'февраля', 'в', 'рамках', 'уголовного', 'дела', 'о', 'незаконном', 'изготовлении', 'взрывчатых', 'веществ', 'части', '1', 'статьи', '223', 'ук', 'рф', 'по', 'словам', '25', 'летнего', 'аспиранта', 'мгу', 'его', 'били', 'и', 'пытали', 'шуруповертом', 'факт', 'насилия', 'подтвердили', 'члены', 'онк', '7', 'февраля', 'математика', 'отпустили', 'но', 'задержали', 'по', 'обвинению', 'в', 'хулиганстве', 'поджог', 'офиса', 'единой', 'россии', 'в', 'ховрино', 'в', 'январе', '2018', 'года', 'статьи', '213', '2', 'ук', 'рф']\n",
      "Tags:   ['O', 'O', 'B-ORGANIZATION', 'B-PERSON', 'I-PERSON', 'O', 'O', 'O', 'O', 'O', 'O', 'B-PERSON', 'I-PERSON', 'O', 'O', 'O', 'O', 'O', 'O', 'B-EVENT', 'I-EVENT', 'I-EVENT', 'O', 'B-FACILITY', 'B-ORGANIZATION', 'I-ORGANIZATION', 'B-PROFESSION', 'B-ORGANIZATION', 'B-PERSON', 'I-PERSON', 'O', 'O', 'O', 'B-ORGANIZATION', 'O', 'O', 'O', 'O', 'B-WORK_OF_ART', 'I-WORK_OF_ART', 'I-WORK_OF_ART', 'I-WORK_OF_ART', 'O', 'O', 'O', 'O', 'O', 'O', 'B-PRODUCT', 'I-PRODUCT', 'B-DATE', 'I-DATE', 'O', 'O', 'O', 'O', 'B-PROFESSION', 'B-PERSON', 'I-PERSON', 'B-PROFESSION', 'I-PROFESSION', 'B-ORGANIZATION', 'I-ORGANIZATION', 'I-ORGANIZATION', 'B-ORGANIZATION', 'I-ORGANIZATION', 'I-ORGANIZATION', 'I-ORGANIZATION', 'I-ORGANIZATION', 'I-ORGANIZATION', 'I-ORGANIZATION', 'I-ORGANIZATION', 'I-ORGANIZATION', 'B-PERSON', 'I-PERSON', 'I-PERSON', 'B-ORGANIZATION', 'O', 'O', 'B-WORK_OF_ART', 'I-WORK_OF_ART', 'I-WORK_OF_ART', 'I-WORK_OF_ART', 'I-WORK_OF_ART', 'I-WORK_OF_ART', 'I-WORK_OF_ART', 'I-WORK_OF_ART', 'I-WORK_OF_ART', 'I-WORK_OF_ART', 'I-WORK_OF_ART', 'I-WORK_OF_ART', 'I-WORK_OF_ART', 'O', 'O', 'O', 'B-DATE', 'I-DATE', 'I-DATE', 'B-PERSON', 'I-PERSON', 'B-EVENT', 'B-DATE', 'I-DATE', 'O', 'O', 'O', 'O', 'O', 'B-CRIME', 'I-CRIME', 'I-CRIME', 'I-CRIME', 'B-LAW', 'B-ORDINAL', 'B-LAW', 'B-ORDINAL', 'B-LAW', 'B-COUNTRY', 'O', 'O', 'B-AGE', 'I-AGE', 'B-PROFESSION', 'B-ORGANIZATION', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ORGANIZATION', 'B-DATE', 'I-DATE', 'B-PROFESSION', 'O', 'O', 'B-EVENT', 'O', 'O', 'O', 'B-CRIME', 'B-EVENT', 'B-FACILITY', 'B-ORGANIZATION', 'I-ORGANIZATION', 'O', 'B-DISTRICT', 'B-DATE', 'I-DATE', 'I-DATE', 'I-DATE', 'O', 'B-LAW', 'B-ORDINAL', 'B-LAW', 'B-COUNTRY']\n"
     ]
    }
   ],
   "source": [
    "first_two_train_samples = prepared_data['train'][:2]\n",
    "for n, sample in enumerate(first_two_train_samples):\n",
    "    # sample is a tuple of sentence_tokens and sentence_tags\n",
    "    tokens, tags = sample\n",
    "    print('Sentence {}'.format(n))\n",
    "    print('Tokens: {}'.format(tokens))\n",
    "    print('Tags:   {}'.format(tags))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ner.corpus import Corpus\n",
    "corp = Corpus(prepared_data, embeddings_file_path=None) # all data is used for training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters: \n",
      "Embeddings 2309400\n",
      "ConvNet 228352\n",
      "Classifier 7740\n",
      "transitions:0 3600\n",
      "Total number of parameters equal 2549092\n",
      "Epoch 0\n",
      "Eval on valid:\n",
      "processed 11830 tokens with 2535 phrases; found: 1312 phrases; correct: 196.\n",
      "\n",
      "precision:  14.94%; recall:  7.73%; FB1:  10.19\n",
      "\n",
      "\n",
      "Epoch 1\n",
      "Eval on valid:\n",
      "processed 11830 tokens with 2535 phrases; found: 842 phrases; correct: 399.\n",
      "\n",
      "precision:  47.39%; recall:  15.74%; FB1:  23.63\n",
      "\n",
      "\n",
      "Epoch 2\n",
      "Eval on valid:\n",
      "processed 11830 tokens with 2535 phrases; found: 1419 phrases; correct: 741.\n",
      "\n",
      "precision:  52.22%; recall:  29.23%; FB1:  37.48\n",
      "\n",
      "\n",
      "Epoch 3\n",
      "Eval on valid:\n",
      "processed 11830 tokens with 2535 phrases; found: 1423 phrases; correct: 841.\n",
      "\n",
      "precision:  59.10%; recall:  33.18%; FB1:  42.50\n",
      "\n",
      "\n",
      "Epoch 4\n",
      "Eval on valid:\n",
      "processed 11830 tokens with 2535 phrases; found: 1574 phrases; correct: 961.\n",
      "\n",
      "precision:  61.05%; recall:  37.91%; FB1:  46.78\n",
      "\n",
      "\n",
      "Epoch 5\n",
      "Eval on valid:\n",
      "processed 11830 tokens with 2535 phrases; found: 1887 phrases; correct: 1086.\n",
      "\n",
      "precision:  57.55%; recall:  42.84%; FB1:  49.12\n",
      "\n",
      "\n",
      "Epoch 6\n",
      "Eval on valid:\n",
      "processed 11830 tokens with 2535 phrases; found: 1987 phrases; correct: 1124.\n",
      "\n",
      "precision:  56.57%; recall:  44.34%; FB1:  49.71\n",
      "\n",
      "\n",
      "Epoch 7\n",
      "Eval on valid:\n",
      "processed 11830 tokens with 2535 phrases; found: 2104 phrases; correct: 1161.\n",
      "\n",
      "precision:  55.18%; recall:  45.80%; FB1:  50.05\n",
      "\n",
      "\n",
      "Epoch 8\n",
      "Eval on valid:\n",
      "processed 11830 tokens with 2535 phrases; found: 2087 phrases; correct: 1174.\n",
      "\n",
      "precision:  56.25%; recall:  46.31%; FB1:  50.80\n",
      "\n",
      "\n",
      "Epoch 9\n",
      "Eval on valid:\n",
      "processed 11830 tokens with 2535 phrases; found: 2038 phrases; correct: 1171.\n",
      "\n",
      "precision:  57.46%; recall:  46.19%; FB1:  51.21\n",
      "\n",
      "\n",
      "Epoch 10\n",
      "Eval on valid:\n",
      "processed 11830 tokens with 2535 phrases; found: 2065 phrases; correct: 1176.\n",
      "\n",
      "precision:  56.95%; recall:  46.39%; FB1:  51.13\n",
      "\n",
      "\n",
      "Epoch 11\n",
      "Eval on valid:\n",
      "processed 11830 tokens with 2535 phrases; found: 2128 phrases; correct: 1193.\n",
      "\n",
      "precision:  56.06%; recall:  47.06%; FB1:  51.17\n",
      "\n",
      "\n",
      "Epoch 12\n",
      "Eval on valid:\n",
      "processed 11830 tokens with 2535 phrases; found: 2154 phrases; correct: 1203.\n",
      "\n",
      "precision:  55.85%; recall:  47.46%; FB1:  51.31\n",
      "\n",
      "\n",
      "Epoch 13\n",
      "Eval on valid:\n",
      "processed 11830 tokens with 2535 phrases; found: 2166 phrases; correct: 1207.\n",
      "\n",
      "precision:  55.72%; recall:  47.61%; FB1:  51.35\n",
      "\n",
      "\n",
      "Epoch 14\n",
      "Eval on valid:\n",
      "processed 11830 tokens with 2535 phrases; found: 2148 phrases; correct: 1208.\n",
      "\n",
      "precision:  56.24%; recall:  47.65%; FB1:  51.59\n",
      "\n",
      "\n",
      "Eval on train:\n",
      "processed 90787 tokens with 21034 phrases; found: 20549 phrases; correct: 17348.\n",
      "\n",
      "precision:  84.42%; recall:  82.48%; FB1:  83.44\n",
      "\n",
      "\tAGE: precision:  89.18%; recall:  92.10%; F1:  90.62 536\n",
      "\n",
      "\tAWARD: precision:  57.47%; recall:  35.46%; F1:  43.86 87\n",
      "\n",
      "\tCITY: precision:  72.62%; recall:  91.01%; F1:  80.78 1227\n",
      "\n",
      "\tCOUNTRY: precision:  90.82%; recall:  95.17%; F1:  92.94 2103\n",
      "\n",
      "\tCRIME: precision:  44.90%; recall:  30.34%; F1:  36.21 98\n",
      "\n",
      "\tDATE: precision:  89.82%; recall:  89.15%; F1:  89.48 2131\n",
      "\n",
      "\tDISEASE: precision:  69.23%; recall:  6.38%; F1:  11.69 13\n",
      "\n",
      "\tDISTRICT: precision:  0.00%; recall:  0.00%; F1:  0.00 0\n",
      "\n",
      "\tEVENT: precision:  82.05%; recall:  83.19%; F1:  82.62 2317\n",
      "\n",
      "\tFACILITY: precision:  41.09%; recall:  41.92%; F1:  41.50 202\n",
      "\n",
      "\tFAMILY: precision:  0.00%; recall:  0.00%; F1:  0.00 0\n",
      "\n",
      "\tIDEOLOGY: precision:  66.27%; recall:  24.23%; F1:  35.48 83\n",
      "\n",
      "\tLANGUAGE: precision:  0.00%; recall:  0.00%; F1:  0.00 0\n",
      "\n",
      "\tLAW: precision:  58.21%; recall:  31.71%; F1:  41.05 67\n",
      "\n",
      "\tLOCATION: precision:  69.57%; recall:  7.62%; F1:  13.73 23\n",
      "\n",
      "\tMONEY: precision:  80.00%; recall:  87.80%; F1:  83.72 135\n",
      "\n",
      "\tNATIONALITY: precision:  69.80%; recall:  54.46%; F1:  61.18 245\n",
      "\n",
      "\tNUMBER: precision:  81.49%; recall:  83.72%; F1:  82.59 940\n",
      "\n",
      "\tORDINAL: precision:  80.80%; recall:  78.64%; F1:  79.71 474\n",
      "\n",
      "\tORGANIZATION: precision:  83.44%; recall:  83.22%; F1:  83.33 2247\n",
      "\n",
      "\tPENALTY: precision:  0.00%; recall:  0.00%; F1:  0.00 0\n",
      "\n",
      "\tPERCENT: precision:  77.78%; recall:  12.73%; F1:  21.87 9\n",
      "\n",
      "\tPERSON: precision:  92.33%; recall:  95.08%; F1:  93.69 4226\n",
      "\n",
      "\tPRODUCT: precision:  79.25%; recall:  22.95%; F1:  35.59 53\n",
      "\n",
      "\tPROFESSION: precision:  86.18%; recall:  91.14%; F1:  88.59 2851\n",
      "\n",
      "\tRELIGION: precision:  0.00%; recall:  0.00%; F1:  0.00 0\n",
      "\n",
      "\tSTATE_OR_PROVINCE: precision:  54.94%; recall:  59.81%; F1:  57.27 344\n",
      "\n",
      "\tTIME: precision:  46.55%; recall:  31.40%; F1:  37.50 58\n",
      "\n",
      "\tWORK_OF_ART: precision:  38.75%; recall:  19.87%; F1:  26.27 80\n",
      "\n",
      "\n",
      "Eval on valid:\n",
      "processed 11830 tokens with 2535 phrases; found: 2148 phrases; correct: 1208.\n",
      "\n",
      "precision:  56.24%; recall:  47.65%; FB1:  51.59\n",
      "\n",
      "\tAGE: precision:  85.14%; recall:  88.73%; F1:  86.90 74\n",
      "\n",
      "\tAWARD: precision:  0.00%; recall:  0.00%; F1:  0.00 2\n",
      "\n",
      "\tCITY: precision:  71.59%; recall:  44.68%; F1:  55.02 88\n",
      "\n",
      "\tCOUNTRY: precision:  84.88%; recall:  76.65%; F1:  80.56 205\n",
      "\n",
      "\tCRIME: precision:  33.33%; recall:  11.76%; F1:  17.39 6\n",
      "\n",
      "\tDATE: precision:  74.52%; recall:  74.81%; F1:  74.67 263\n",
      "\n",
      "\tDISEASE: precision:  0.00%; recall:  0.00%; F1:  0.00 0\n",
      "\n",
      "\tDISTRICT: precision:  0.00%; recall:  0.00%; F1:  0.00 0\n",
      "\n",
      "\tEVENT: precision:  45.00%; recall:  39.60%; F1:  42.13 220\n",
      "\n",
      "\tFACILITY: precision:  0.00%; recall:  0.00%; F1:  0.00 7\n",
      "\n",
      "\tFAMILY: precision:  0.00%; recall:  0.00%; F1:  0.00 0\n",
      "\n",
      "\tIDEOLOGY: precision:  66.67%; recall:  17.39%; F1:  27.59 6\n",
      "\n",
      "\tLANGUAGE: precision:  0.00%; recall:  0.00%; F1:  0.00 0\n",
      "\n",
      "\tLAW: precision:  100.00%; recall:  6.67%; F1:  12.50 1\n",
      "\n",
      "\tLOCATION: precision:  0.00%; recall:  0.00%; F1:  0.00 1\n",
      "\n",
      "\tMONEY: precision:  71.43%; recall:  66.67%; F1:  68.97 28\n",
      "\n",
      "\tNATIONALITY: precision:  32.14%; recall:  18.00%; F1:  23.08 28\n",
      "\n",
      "\tNUMBER: precision:  61.18%; recall:  57.14%; F1:  59.09 85\n",
      "\n",
      "\tORDINAL: precision:  50.00%; recall:  58.70%; F1:  54.00 54\n",
      "\n",
      "\tORGANIZATION: precision:  30.96%; recall:  40.32%; F1:  35.03 323\n",
      "\n",
      "\tPENALTY: precision:  0.00%; recall:  0.00%; F1:  0.00 0\n",
      "\n",
      "\tPERCENT: precision:  0.00%; recall:  0.00%; F1:  0.00 1\n",
      "\n",
      "\tPERSON: precision:  57.38%; recall:  39.02%; F1:  46.45 359\n",
      "\n",
      "\tPRODUCT: precision:  0.00%; recall:  0.00%; F1:  0.00 0\n",
      "\n",
      "\tPROFESSION: precision:  47.96%; recall:  54.15%; F1:  50.87 367\n",
      "\n",
      "\tRELIGION: precision:  0.00%; recall:  0.00%; F1:  0.00 0\n",
      "\n",
      "\tSTATE_OR_PROVINCE: precision:  55.17%; recall:  29.09%; F1:  38.10 29\n",
      "\n",
      "\tTIME: precision:  0.00%; recall:  0.00%; F1:  0.00 1\n",
      "\n",
      "\tWORK_OF_ART: precision:  0.00%; recall:  0.00%; F1:  0.00 0\n",
      "\n",
      "\n",
      "Eval on test:\n",
      "processed 10565 tokens with 2390 phrases; found: 2048 phrases; correct: 1212.\n",
      "\n",
      "precision:  59.18%; recall:  50.71%; FB1:  54.62\n",
      "\n",
      "\tAGE: precision:  77.78%; recall:  86.15%; F1:  81.75 72\n",
      "\n",
      "\tAWARD: precision:  0.00%; recall:  0.00%; F1:  0.00 1\n",
      "\n",
      "\tCITY: precision:  56.73%; recall:  47.20%; F1:  51.53 104\n",
      "\n",
      "\tCOUNTRY: precision:  85.04%; recall:  73.98%; F1:  79.13 234\n",
      "\n",
      "\tCRIME: precision:  50.00%; recall:  11.11%; F1:  18.18 2\n",
      "\n",
      "\tDATE: precision:  73.96%; recall:  75.38%; F1:  74.67 265\n",
      "\n",
      "\tDISEASE: precision:  0.00%; recall:  0.00%; F1:  0.00 0\n",
      "\n",
      "\tDISTRICT: precision:  0.00%; recall:  0.00%; F1:  0.00 0\n",
      "\n",
      "\tEVENT: precision:  42.57%; recall:  36.13%; F1:  39.09 202\n",
      "\n",
      "\tFACILITY: precision:  0.00%; recall:  0.00%; F1:  0.00 5\n",
      "\n",
      "\tIDEOLOGY: precision:  50.00%; recall:  6.67%; F1:  11.76 2\n",
      "\n",
      "\tLANGUAGE: precision:  0.00%; recall:  0.00%; F1:  0.00 0\n",
      "\n",
      "\tLAW: precision:  0.00%; recall:  0.00%; F1:  0.00 1\n",
      "\n",
      "\tLOCATION: precision:  100.00%; recall:  4.35%; F1:  8.33 1\n",
      "\n",
      "\tMONEY: precision:  44.44%; recall:  100.00%; F1:  61.54 9\n",
      "\n",
      "\tNATIONALITY: precision:  31.03%; recall:  20.93%; F1:  25.00 29\n",
      "\n",
      "\tNUMBER: precision:  60.71%; recall:  68.00%; F1:  64.15 112\n",
      "\n",
      "\tORDINAL: precision:  75.38%; recall:  61.25%; F1:  67.59 65\n",
      "\n",
      "\tORGANIZATION: precision:  39.13%; recall:  45.19%; F1:  41.94 276\n",
      "\n",
      "\tPENALTY: precision:  0.00%; recall:  0.00%; F1:  0.00 0\n",
      "\n",
      "\tPERCENT: precision:  0.00%; recall:  0.00%; F1:  0.00 0\n",
      "\n",
      "\tPERSON: precision:  70.31%; recall:  47.58%; F1:  56.75 293\n",
      "\n",
      "\tPRODUCT: precision:  0.00%; recall:  0.00%; F1:  0.00 0\n",
      "\n",
      "\tPROFESSION: precision:  47.49%; recall:  60.07%; F1:  53.05 339\n",
      "\n",
      "\tRELIGION: precision:  0.00%; recall:  0.00%; F1:  0.00 0\n",
      "\n",
      "\tSTATE_OR_PROVINCE: precision:  30.43%; recall:  17.50%; F1:  22.22 23\n",
      "\n",
      "\tTIME: precision:  0.00%; recall:  0.00%; F1:  0.00 4\n",
      "\n",
      "\tWORK_OF_ART: precision:  11.11%; recall:  3.57%; F1:  5.41 9\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from ner.network import NER\n",
    "import tensorflow as tf\n",
    "\n",
    "learning_params = {'dropout_rate': 0.5,\n",
    "                'epochs': 15,\n",
    "                'learning_rate': 0.005,\n",
    "                'batch_size': 8,\n",
    "                'learning_rate_decay': 0.707}\n",
    "\n",
    "model_params = {\"filter_width\": 7,\n",
    "            \"embeddings_dropout\": True,\n",
    "            \"n_filters\": [\n",
    "                128, 128,\n",
    "            ],\n",
    "            \"token_embeddings_dim\": 100,\n",
    "            \"char_embeddings_dim\": 25,\n",
    "            \"use_batch_norm\": True,\n",
    "            \"use_crf\": True,\n",
    "            \"net_type\": 'cnn',\n",
    "            \"use_capitalization\": True,\n",
    "            }\n",
    "\n",
    "net = NER(corp, **model_params) # initialise the model\n",
    "results = net.fit(**learning_params) # train the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_back(tokens, tags):\n",
    "    \"\"\"\n",
    "    convert tokens and tags back to a sentence and a list of entities\n",
    "    \"\"\"\n",
    "    sentence = \"\"\n",
    "    entities = []\n",
    "    current_entity = None\n",
    "    start_index = 0\n",
    "    for token, tag in zip(tokens, tags):\n",
    "        if tag.startswith(\"B-\"):  # If this is the beginning of the entity\n",
    "            if current_entity is not None:  # if there is an entity in progress\n",
    "                entities.append([start_index, len(sentence.strip()), current_entity])\n",
    "            current_entity = tag[2:]\n",
    "            sentence += \" \" + token\n",
    "            start_index = len(sentence.strip()) - len(token)\n",
    "        elif tag.startswith(\"I-\"):  # if this is the intermediate part of the entity\n",
    "            if current_entity is not None:  # if there is an entity in progress\n",
    "                sentence += \" \" + token\n",
    "        else:  # if this is not an entity\n",
    "            if current_entity is not None:  # if there is an entity in progress\n",
    "                entities.append([start_index, len(sentence.strip()), current_entity])\n",
    "                current_entity = None\n",
    "            sentence += \" \" + token\n",
    "    if current_entity is not None:  # if there is an entity in progress at the end of the sentence\n",
    "        entities.append([start_index, len(sentence.strip()), current_entity])\n",
    "    return entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 65/65 [00:05<00:00, 10.93it/s]\n"
     ]
    }
   ],
   "source": [
    "from ner.utils import tokenize, lemmatize\n",
    "\n",
    "def save_to_jsonl(filename, data): # save the data to a JSONL file\n",
    "    with open(filename, 'w', encoding='utf-8') as f:\n",
    "        for entities in data:\n",
    "            json_line = {\"ners\": entities}\n",
    "            f.write(json.dumps(json_line, ensure_ascii=False) + '\\n')\n",
    "\n",
    "def predict(sentence, network):\n",
    "    # split sentence into tokens\n",
    "    tokens = tokenize(sentence)\n",
    "    # lemmatize tokens\n",
    "    tokens_lemmas = lemmatize(tokens)\n",
    "    # predict tags\n",
    "    tags = network.predict_for_token_batch([tokens_lemmas])[0]\n",
    "    return tokens, tags\n",
    "\n",
    "output = []\n",
    "for sentence in tqdm(dev_data):\n",
    "    tokens, tags = predict(sentence[\"senences\"], net) # predict tags for the sentence\n",
    "    output.append(convert_back(tokens, tags)) # convert tokens and tags back to entities\n",
    "\n",
    "save_to_jsonl(\"test.jsonl\", output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
