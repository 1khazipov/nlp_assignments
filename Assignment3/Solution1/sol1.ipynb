{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def read_jsonl_file(file_path):\n",
    "    \"\"\"\n",
    "    read a JSONL file and return its contents as a list of dictionaries\n",
    "    \"\"\"\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        return [json.loads(line) for line in f]\n",
    "\n",
    "\n",
    "train_data = read_jsonl_file(\"../data/train.jsonl\")\n",
    "dev_data = read_jsonl_file('../data/dev.jsonl')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data processings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Бостон взорвали Тамерлан и Джохар Царнаевы из Северного Кавказа\\n\\n19 апреля 2013 года в пригороде Бостона  проходит спецоперация по поимке 19-летнего Джохара Царнаева, подозреваемого в теракте на Бостонском марафоне 15 апреля и в смертельном ранении полицейского на кампусе Массачусетского технологического института 18 апреля.\\n\\nВторой подозреваемый, его брат, 26-летний Тамерлан Царнаев, был ранен в перестрелке в Уотертауне  и позже скончался в больнице.\\n\\nУотертаун и его окрестности фактически переведены на осадное положение: окрестности оцеплены, дороги перекрыты, магазины и бизнесы закрыты, жителей просят не выходить из домов и не приближаться к окнам, над районом спецоперации перекрыты полёты авиации.\\n\\nВ Бостоне приостановлена работа общественного транспорта, включая метро, автобусы, такси и пригородные поезда. Отменены занятия в Гарварде, Массачусетском технологическом институте, Университете Саффолка, Бостонском университете и во всех городских школах.\\n\\nНа сайте ФБР опубликованы фото и видео разыскиваемого.\\n\\n19-летний студент Университета штата Массачусетс Джохар Царнаев обучался в средней школе Махачкалы, затем в школе Кембриджа (район Бостона), входил в список стипендиатов Кембриджа.\\n\\nСекретарь директора школы №\\xa01 Махачкалы Ирина Бандурина подтвердила «Эху Москвы», что Джохар Царнаев учился в данном учебном заведении, но покинул его, не закончив первый класс.\\n\\nОдин из братьев приехал в США вместе с родителями в 2002 году, а другой — самостоятельно в 2004 году.\\n\\nИнцидент произошел спустя несколько дней после теракта на Бостонском марафоне, во время которого прогремели два взрыва.\\nИх жертвами стали три человека, более 180 получили ранения.\\n',\n",
       " [(0, 6, 'CITY'),\n",
       "  (7, 15, 'EVENT'),\n",
       "  (16, 24, 'PERSON'),\n",
       "  (16, 42, 'FAMILY'),\n",
       "  (27, 42, 'PERSON'),\n",
       "  (34, 42, 'PERSON'),\n",
       "  (46, 63, 'LOCATION'),\n",
       "  (56, 63, 'LOCATION'),\n",
       "  (65, 79, 'DATE'),\n",
       "  (87, 104, 'LOCATION'),\n",
       "  (97, 104, 'CITY'),\n",
       "  (115, 137, 'EVENT'),\n",
       "  (138, 148, 'AGE'),\n",
       "  (149, 165, 'PERSON'),\n",
       "  (184, 191, 'CRIME'),\n",
       "  (195, 205, 'CITY'),\n",
       "  (195, 214, 'EVENT'),\n",
       "  (215, 224, 'DATE'),\n",
       "  (229, 261, 'CRIME'),\n",
       "  (273, 288, 'STATE_OR_PROVINCE'),\n",
       "  (273, 315, 'ORGANIZATION'),\n",
       "  (316, 325, 'DATE'),\n",
       "  (328, 334, 'ORDINAL'),\n",
       "  (360, 369, 'AGE'),\n",
       "  (370, 386, 'PERSON'),\n",
       "  (392, 397, 'EVENT'),\n",
       "  (400, 411, 'EVENT'),\n",
       "  (414, 424, 'CITY'),\n",
       "  (434, 443, 'EVENT'),\n",
       "  (457, 466, 'CITY'),\n",
       "  (714, 721, 'CITY'),\n",
       "  (842, 850, 'ORGANIZATION'),\n",
       "  (852, 866, 'STATE_OR_PROVINCE'),\n",
       "  (852, 892, 'ORGANIZATION'),\n",
       "  (894, 915, 'ORGANIZATION'),\n",
       "  (907, 915, 'CITY'),\n",
       "  (917, 927, 'CITY'),\n",
       "  (917, 940, 'ORGANIZATION'),\n",
       "  (979, 982, 'ORGANIZATION'),\n",
       "  (1026, 1035, 'AGE'),\n",
       "  (1044, 1074, 'ORGANIZATION'),\n",
       "  (1063, 1074, 'STATE_OR_PROVINCE'),\n",
       "  (1075, 1089, 'PERSON'),\n",
       "  (1115, 1124, 'CITY'),\n",
       "  (1140, 1149, 'DISTRICT'),\n",
       "  (1157, 1164, 'CITY'),\n",
       "  (1183, 1195, 'AWARD'),\n",
       "  (1183, 1205, 'AWARD'),\n",
       "  (1196, 1205, 'DISTRICT'),\n",
       "  (1208, 1227, 'PROFESSION'),\n",
       "  (1208, 1247, 'PROFESSION'),\n",
       "  (1228, 1247, 'ORGANIZATION'),\n",
       "  (1238, 1247, 'CITY'),\n",
       "  (1248, 1263, 'PERSON'),\n",
       "  (1277, 1287, 'ORGANIZATION'),\n",
       "  (1294, 1308, 'PERSON'),\n",
       "  (1372, 1378, 'ORDINAL'),\n",
       "  (1413, 1416, 'COUNTRY'),\n",
       "  (1437, 1448, 'DATE'),\n",
       "  (1476, 1487, 'DATE'),\n",
       "  (1537, 1544, 'EVENT'),\n",
       "  (1548, 1558, 'CITY'),\n",
       "  (1548, 1567, 'EVENT'),\n",
       "  (1559, 1567, 'EVENT'),\n",
       "  (1598, 1601, 'NUMBER'),\n",
       "  (1602, 1608, 'EVENT'),\n",
       "  (1613, 1627, 'EVENT'),\n",
       "  (1628, 1631, 'NUMBER'),\n",
       "  (1642, 1651, 'NUMBER'),\n",
       "  (1661, 1668, 'EVENT')])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def process_data(data):\n",
    "    processed_data = []\n",
    "    for entry in data:\n",
    "        sentences = entry['sentences']\n",
    "        ners = sorted(entry['ners'], key=lambda x: x[1] - x[0])\n",
    "        modified_ners = sorted([(entity[0], entity[1] + 1, entity[2]) for entity in ners])\n",
    "        processed_data.append((sentences, modified_ners))\n",
    "    return processed_data\n",
    "\n",
    "prepared_data = process_data(train_data)\n",
    "prepared_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 519/519 [00:02<00:00, 196.81it/s]\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from tqdm import tqdm\n",
    "\n",
    "def convert_dataset(dataset):\n",
    "    converted_dataset = []\n",
    "    for sentence, entities in tqdm(dataset):\n",
    "        tokens = re.findall(r'\\b\\w+\\b', sentence.lower())  # use a regular expression to split into words\n",
    "        tags = ['O'] * len(tokens)  # initialise the tags for each word as an 'O' (not an entity)\n",
    "        for start, end, entity_type in entities:\n",
    "            start_word_index = len(re.findall(r'\\b\\w+\\b', sentence[:start].lower()))  # find the index of the beginning of the word\n",
    "            end_word_index = len(re.findall(r'\\b\\w+\\b', sentence[:end].lower())) - 1  # find the index of the end of the word\n",
    "            if start_word_index == end_word_index:  # if the entity is within the same word\n",
    "                # set tag to B-<entity> for the beginning of the entity\n",
    "                tags[start_word_index] = 'B-' + entity_type\n",
    "            else:\n",
    "                tags[start_word_index] = 'B-' + entity_type\n",
    "                for i in range(start_word_index + 1, end_word_index + 1):\n",
    "                    tags[i] = 'I-' + entity_type # set tag to I-<entity> for the intermediate words\n",
    "        converted_dataset.append((tokens, tags))\n",
    "    return converted_dataset\n",
    "\n",
    "prepared_data = convert_dataset(prepared_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "prepared_data_train, prepared_data_test = train_test_split(prepared_data, train_size=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "prepared_data = {}\n",
    "prepared_data['train'] = prepared_data_train\n",
    "prepared_data['valid'], prepared_data['test'] =  train_test_split(prepared_data_test, test_size=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence 0\n",
      "Tokens: ['миллиардер', 'абызов', 'стал', 'советником', 'медведева', 'председатель', 'совета', 'директоров', 'инжиниринговой', 'компании', 'группа', 'е4', 'михаил', 'абызов', 'назначен', 'советником', 'президента', 'россии', 'дмитрия', 'медведева', 'об', 'этом', 'сообщается', '18', 'января', 'на', 'сайте', 'кремля', 'как', 'сообщает', 'интерфакс', 'пресс', 'секретарь', 'президента', 'наталья', 'тимакова', 'назвала', 'среди', 'задач', 'абызова', 'координацию', 'работы', 'большого', 'правительства', 'и', 'выработку', 'механизмов', 'его', 'взаимодействия', 'с', 'госорганами', 'кроме', 'того', 'механизмы', 'работы', 'большого', 'правительства', 'будут', 'отрабатываться', 'в', 'рамках', 'рабочей', 'группы', 'которая', 'будет', 'создана', 'в', 'ближайшее', 'время', 'по', 'словам', 'тимаковой', 'группу', 'возглавит', 'глава', 'администрации', 'президента', 'сергей', 'иванов', 'а', 'его', 'заместителями', 'станут', 'абызов', 'и', 'помощник', 'президента', 'аркадий', 'дворкович', '39', 'летний', 'михаил', 'абызов', 'занимает', '76', 'ю', 'строчку', 'в', 'списке', 'богатейших', 'бизнесменов', 'россии', 'от', 'журнала', 'forbes', 'его', 'состояние', 'оценивается', 'в', '1', '2', 'миллиарда', 'долларов', 'ранее', 'абызов', 'уже', 'упоминался', 'в', 'прессе', 'как', 'координатор', 'большого', 'правительства', 'так', 'же', 'он', 'координировал', 'работу', 'общественного', 'комитета', 'сторонников', 'медведева', 'дмитрий', 'медведев', 'выдвинул', 'концепцию', 'большого', 'правительства', 'в', 'октябре', '2011', 'года', 'тогда', 'он', 'сообщил', 'что', 'в', 'новую', 'структуру', 'с', 'совещательными', 'полномочиями', 'войдут', 'журналисты', 'бизнесмены', 'и', 'представители', 'гражданского', 'общества', 'при', 'этом', 'медведев', 'пообещал', 'в', 'случае', 'победы', 'владимира', 'путина', 'на', 'президентских', 'выборах', 'в', 'этом', 'случае', 'нынешний', 'президент', 'как', 'ожидается', 'займет', 'пост', 'премьер', 'министра', 'сформировать', 'традиционное', 'правительство', 'из', 'абсолютно', 'новых', 'людей']\n",
      "Tags:   ['O', 'B-PERSON', 'O', 'B-PROFESSION', 'B-PERSON', 'B-PROFESSION', 'B-ORGANIZATION', 'I-ORGANIZATION', 'O', 'O', 'B-ORGANIZATION', 'I-ORGANIZATION', 'B-PERSON', 'I-PERSON', 'B-EVENT', 'B-PROFESSION', 'B-PROFESSION', 'B-COUNTRY', 'B-PERSON', 'I-PERSON', 'O', 'O', 'O', 'B-DATE', 'I-DATE', 'O', 'O', 'B-ORGANIZATION', 'O', 'O', 'B-ORGANIZATION', 'B-PROFESSION', 'I-PROFESSION', 'B-PROFESSION', 'B-PERSON', 'I-PERSON', 'O', 'O', 'O', 'B-PERSON', 'O', 'O', 'B-ORGANIZATION', 'I-ORGANIZATION', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ORGANIZATION', 'I-ORGANIZATION', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-DATE', 'I-DATE', 'I-DATE', 'O', 'O', 'B-PERSON', 'O', 'O', 'B-PROFESSION', 'B-ORGANIZATION', 'B-PROFESSION', 'B-PERSON', 'I-PERSON', 'O', 'O', 'O', 'O', 'B-PERSON', 'O', 'B-PROFESSION', 'B-PROFESSION', 'B-PERSON', 'I-PERSON', 'B-AGE', 'I-AGE', 'B-PERSON', 'I-PERSON', 'O', 'B-ORDINAL', 'I-ORDINAL', 'O', 'O', 'O', 'O', 'B-PROFESSION', 'B-COUNTRY', 'O', 'O', 'B-ORGANIZATION', 'O', 'O', 'O', 'O', 'B-MONEY', 'I-MONEY', 'I-MONEY', 'I-MONEY', 'O', 'B-PERSON', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ORGANIZATION', 'I-ORGANIZATION', 'I-ORGANIZATION', 'B-PERSON', 'B-PERSON', 'I-PERSON', 'O', 'O', 'B-ORGANIZATION', 'I-ORGANIZATION', 'B-DATE', 'I-DATE', 'I-DATE', 'I-DATE', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-PROFESSION', 'B-PROFESSION', 'O', 'O', 'O', 'O', 'O', 'O', 'B-PERSON', 'O', 'O', 'O', 'O', 'B-PERSON', 'I-PERSON', 'O', 'B-EVENT', 'I-EVENT', 'O', 'O', 'O', 'O', 'B-PROFESSION', 'O', 'O', 'O', 'O', 'B-PROFESSION', 'I-PROFESSION', 'O', 'O', 'B-ORGANIZATION', 'O', 'O', 'O', 'O']\n",
      "Sentence 1\n",
      "Tokens: ['глава', 'мвф', 'арестован', 'в', 'нью', 'йорке', 'доминик', 'стросс', 'кан', 'директор', 'международного', 'валютного', 'фонда', 'по', 'сообщению', 'газет', 'new', 'york', 'post', 'new', 'york', 'times', 'и', 'других', 'американских', 'и', 'мировых', 'сми', 'глава', 'международного', 'фонда', 'доминик', 'стросс', 'кан', 'арестован', 'в', 'нью', 'йорке', 'по', 'подозрению', 'в', 'сексуальном', 'домогательстве', '62', 'летнего', 'стросс', 'кана', 'арестовали', 'в', 'салоне', 'бизнесс', 'класса', 'самолета', 'air', 'france', 'в', 'нью', 'йоркском', 'аэропорту', 'кеннеди', 'за', 'две', 'минуты', 'до', 'вылета', 'лайнера', 'в', 'париж', 'сейчас', 'глава', 'мвф', 'находится', 'в', 'полицейском', 'участке', 'источники', 'в', 'полиции', 'сообщают', 'что', 'в', 'субботу', 'около', 'полудня', 'в', 'гостиничный', 'номер', 'в', 'котором', 'проживал', 'стросс', 'кан', 'пришла', 'горничная', 'постоялец', 'набросился', 'на', 'нее', 'повалил', 'на', 'кровать', 'и', 'домогался', 'затем', 'он', 'отпустил', 'горничную', 'а', 'сам', 'уехал', 'в', 'аэропорт', 'по', 'другим', 'сведениям', 'девушка', 'оказала', 'мужчине', 'сопротивление', 'и', 'смогла', 'вырваться', 'из', 'номера', 'из', 'за', 'ареста', 'под', 'угрозой', 'срыва', 'встреча', 'стросс', 'кана', 'с', 'канцлером', 'германии', 'ангелой', 'меркель', 'назначенная', 'на', 'воскресенье', 'доминик', 'стросс', 'кан', 'член', 'социалистической', 'партии', 'франции', 'и', 'рассматривается', 'как', 'главный', 'соперник', 'французского', 'президента', 'николя', 'саркози', 'на', 'предстоящих', 'в', '2012', 'году', 'выборах', 'некоторые', 'французские', 'политологи', 'обвиняли', 'саркози', 'в', 'том', 'что', 'он', 'развязал', 'грязную', 'кампанию', 'против', 'стросс', 'кана', 'упирая', 'на', 'достаточно', 'разгульный', 'образ', 'жизни', 'последнего', 'в', 'частности', 'говорилось', 'что', 'стросс', 'кан', 'шьет', 'себе', 'костюмы', 'у', 'того', 'же', 'портного', 'что', 'и', 'барак', 'обама', 'однако', 'доминик', 'стросс', 'кан', 'оказывался', 'в', 'щекотливом', 'положении', 'и', 'без', 'помощи', 'соперников', 'на', 'выборах', 'так', 'в', '2007', 'году', 'он', 'публично', 'признал', 'связь', 'с', 'одной', 'из', 'своих', 'подчиненных', 'работающей', 'в', 'международном', 'валютном', 'фонде', 'между', 'тем', 'глава', 'фонда', 'женат', 'его', 'супруга', 'энн', 'синклер', 'известный', 'французский', 'телевизионный', 'журналист']\n",
      "Tags:   ['B-PROFESSION', 'B-ORGANIZATION', 'B-EVENT', 'O', 'B-CITY', 'I-CITY', 'B-PERSON', 'I-PERSON', 'I-PERSON', 'B-PROFESSION', 'B-ORGANIZATION', 'I-ORGANIZATION', 'I-ORGANIZATION', 'O', 'O', 'O', 'B-ORGANIZATION', 'I-ORGANIZATION', 'I-ORGANIZATION', 'B-ORGANIZATION', 'I-ORGANIZATION', 'I-ORGANIZATION', 'O', 'O', 'B-COUNTRY', 'O', 'O', 'O', 'B-PROFESSION', 'B-ORGANIZATION', 'I-ORGANIZATION', 'B-PERSON', 'I-PERSON', 'I-PERSON', 'B-EVENT', 'O', 'B-CITY', 'I-CITY', 'O', 'O', 'O', 'B-CRIME', 'I-CRIME', 'B-AGE', 'I-AGE', 'B-PERSON', 'I-PERSON', 'B-EVENT', 'O', 'O', 'O', 'O', 'B-FACILITY', 'B-ORGANIZATION', 'I-ORGANIZATION', 'O', 'B-CITY', 'I-CITY', 'B-FACILITY', 'B-PERSON', 'B-TIME', 'I-TIME', 'I-TIME', 'O', 'O', 'O', 'O', 'B-CITY', 'O', 'B-PROFESSION', 'B-ORGANIZATION', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-TIME', 'I-TIME', 'I-TIME', 'I-TIME', 'O', 'O', 'O', 'O', 'O', 'O', 'B-PERSON', 'I-PERSON', 'O', 'B-PROFESSION', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-PROFESSION', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-EVENT', 'O', 'O', 'O', 'O', 'B-PERSON', 'I-PERSON', 'O', 'B-PROFESSION', 'B-COUNTRY', 'B-PERSON', 'I-PERSON', 'O', 'O', 'B-DATE', 'B-PERSON', 'I-PERSON', 'I-PERSON', 'O', 'B-ORGANIZATION', 'I-ORGANIZATION', 'B-COUNTRY', 'O', 'O', 'O', 'O', 'O', 'B-PROFESSION', 'B-PROFESSION', 'B-PERSON', 'I-PERSON', 'O', 'O', 'B-DATE', 'I-DATE', 'I-DATE', 'B-EVENT', 'O', 'B-COUNTRY', 'B-PROFESSION', 'O', 'B-PERSON', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-PERSON', 'I-PERSON', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-PERSON', 'I-PERSON', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-PERSON', 'I-PERSON', 'O', 'B-PERSON', 'I-PERSON', 'I-PERSON', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-DATE', 'I-DATE', 'I-DATE', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ORGANIZATION', 'I-ORGANIZATION', 'I-ORGANIZATION', 'O', 'O', 'B-PROFESSION', 'I-PROFESSION', 'O', 'O', 'O', 'B-PERSON', 'I-PERSON', 'O', 'B-NATIONALITY', 'B-PROFESSION', 'B-PROFESSION']\n"
     ]
    }
   ],
   "source": [
    "first_two_train_samples = prepared_data['train'][:2]\n",
    "for n, sample in enumerate(first_two_train_samples):\n",
    "    # sample is a tuple of sentence_tokens and sentence_tags\n",
    "    tokens, tags = sample\n",
    "    print('Sentence {}'.format(n))\n",
    "    print('Tokens: {}'.format(tokens))\n",
    "    print('Tags:   {}'.format(tags))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ner.corpus import Corpus\n",
    "corp = Corpus(prepared_data, embeddings_file_path=None) # all data is used for training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters: \n",
      "Embeddings 2309400\n",
      "ConvNet 228352\n",
      "Classifier 7740\n",
      "transitions:0 3600\n",
      "Total number of parameters equal 2549092\n",
      "Epoch 0\n",
      "Eval on valid:\n",
      "processed 11830 tokens with 2535 phrases; found: 1312 phrases; correct: 196.\n",
      "\n",
      "precision:  14.94%; recall:  7.73%; FB1:  10.19\n",
      "\n",
      "\n",
      "Epoch 1\n",
      "Eval on valid:\n",
      "processed 11830 tokens with 2535 phrases; found: 842 phrases; correct: 399.\n",
      "\n",
      "precision:  47.39%; recall:  15.74%; FB1:  23.63\n",
      "\n",
      "\n",
      "Epoch 2\n",
      "Eval on valid:\n",
      "processed 11830 tokens with 2535 phrases; found: 1419 phrases; correct: 741.\n",
      "\n",
      "precision:  52.22%; recall:  29.23%; FB1:  37.48\n",
      "\n",
      "\n",
      "Epoch 3\n",
      "Eval on valid:\n",
      "processed 11830 tokens with 2535 phrases; found: 1423 phrases; correct: 841.\n",
      "\n",
      "precision:  59.10%; recall:  33.18%; FB1:  42.50\n",
      "\n",
      "\n",
      "Epoch 4\n",
      "Eval on valid:\n",
      "processed 11830 tokens with 2535 phrases; found: 1574 phrases; correct: 961.\n",
      "\n",
      "precision:  61.05%; recall:  37.91%; FB1:  46.78\n",
      "\n",
      "\n",
      "Epoch 5\n",
      "Eval on valid:\n",
      "processed 11830 tokens with 2535 phrases; found: 1887 phrases; correct: 1086.\n",
      "\n",
      "precision:  57.55%; recall:  42.84%; FB1:  49.12\n",
      "\n",
      "\n",
      "Epoch 6\n",
      "Eval on valid:\n",
      "processed 11830 tokens with 2535 phrases; found: 1987 phrases; correct: 1124.\n",
      "\n",
      "precision:  56.57%; recall:  44.34%; FB1:  49.71\n",
      "\n",
      "\n",
      "Epoch 7\n",
      "Eval on valid:\n",
      "processed 11830 tokens with 2535 phrases; found: 2104 phrases; correct: 1161.\n",
      "\n",
      "precision:  55.18%; recall:  45.80%; FB1:  50.05\n",
      "\n",
      "\n",
      "Epoch 8\n",
      "Eval on valid:\n",
      "processed 11830 tokens with 2535 phrases; found: 2087 phrases; correct: 1174.\n",
      "\n",
      "precision:  56.25%; recall:  46.31%; FB1:  50.80\n",
      "\n",
      "\n",
      "Epoch 9\n",
      "Eval on valid:\n",
      "processed 11830 tokens with 2535 phrases; found: 2038 phrases; correct: 1171.\n",
      "\n",
      "precision:  57.46%; recall:  46.19%; FB1:  51.21\n",
      "\n",
      "\n",
      "Epoch 10\n",
      "Eval on valid:\n",
      "processed 11830 tokens with 2535 phrases; found: 2065 phrases; correct: 1176.\n",
      "\n",
      "precision:  56.95%; recall:  46.39%; FB1:  51.13\n",
      "\n",
      "\n",
      "Epoch 11\n",
      "Eval on valid:\n",
      "processed 11830 tokens with 2535 phrases; found: 2128 phrases; correct: 1193.\n",
      "\n",
      "precision:  56.06%; recall:  47.06%; FB1:  51.17\n",
      "\n",
      "\n",
      "Epoch 12\n",
      "Eval on valid:\n",
      "processed 11830 tokens with 2535 phrases; found: 2154 phrases; correct: 1203.\n",
      "\n",
      "precision:  55.85%; recall:  47.46%; FB1:  51.31\n",
      "\n",
      "\n",
      "Epoch 13\n",
      "Eval on valid:\n",
      "processed 11830 tokens with 2535 phrases; found: 2166 phrases; correct: 1207.\n",
      "\n",
      "precision:  55.72%; recall:  47.61%; FB1:  51.35\n",
      "\n",
      "\n",
      "Epoch 14\n",
      "Eval on valid:\n",
      "processed 11830 tokens with 2535 phrases; found: 2148 phrases; correct: 1208.\n",
      "\n",
      "precision:  56.24%; recall:  47.65%; FB1:  51.59\n",
      "\n",
      "\n",
      "Eval on train:\n",
      "processed 90787 tokens with 21034 phrases; found: 20549 phrases; correct: 17348.\n",
      "\n",
      "precision:  84.42%; recall:  82.48%; FB1:  83.44\n",
      "\n",
      "\tAGE: precision:  89.18%; recall:  92.10%; F1:  90.62 536\n",
      "\n",
      "\tAWARD: precision:  57.47%; recall:  35.46%; F1:  43.86 87\n",
      "\n",
      "\tCITY: precision:  72.62%; recall:  91.01%; F1:  80.78 1227\n",
      "\n",
      "\tCOUNTRY: precision:  90.82%; recall:  95.17%; F1:  92.94 2103\n",
      "\n",
      "\tCRIME: precision:  44.90%; recall:  30.34%; F1:  36.21 98\n",
      "\n",
      "\tDATE: precision:  89.82%; recall:  89.15%; F1:  89.48 2131\n",
      "\n",
      "\tDISEASE: precision:  69.23%; recall:  6.38%; F1:  11.69 13\n",
      "\n",
      "\tDISTRICT: precision:  0.00%; recall:  0.00%; F1:  0.00 0\n",
      "\n",
      "\tEVENT: precision:  82.05%; recall:  83.19%; F1:  82.62 2317\n",
      "\n",
      "\tFACILITY: precision:  41.09%; recall:  41.92%; F1:  41.50 202\n",
      "\n",
      "\tFAMILY: precision:  0.00%; recall:  0.00%; F1:  0.00 0\n",
      "\n",
      "\tIDEOLOGY: precision:  66.27%; recall:  24.23%; F1:  35.48 83\n",
      "\n",
      "\tLANGUAGE: precision:  0.00%; recall:  0.00%; F1:  0.00 0\n",
      "\n",
      "\tLAW: precision:  58.21%; recall:  31.71%; F1:  41.05 67\n",
      "\n",
      "\tLOCATION: precision:  69.57%; recall:  7.62%; F1:  13.73 23\n",
      "\n",
      "\tMONEY: precision:  80.00%; recall:  87.80%; F1:  83.72 135\n",
      "\n",
      "\tNATIONALITY: precision:  69.80%; recall:  54.46%; F1:  61.18 245\n",
      "\n",
      "\tNUMBER: precision:  81.49%; recall:  83.72%; F1:  82.59 940\n",
      "\n",
      "\tORDINAL: precision:  80.80%; recall:  78.64%; F1:  79.71 474\n",
      "\n",
      "\tORGANIZATION: precision:  83.44%; recall:  83.22%; F1:  83.33 2247\n",
      "\n",
      "\tPENALTY: precision:  0.00%; recall:  0.00%; F1:  0.00 0\n",
      "\n",
      "\tPERCENT: precision:  77.78%; recall:  12.73%; F1:  21.87 9\n",
      "\n",
      "\tPERSON: precision:  92.33%; recall:  95.08%; F1:  93.69 4226\n",
      "\n",
      "\tPRODUCT: precision:  79.25%; recall:  22.95%; F1:  35.59 53\n",
      "\n",
      "\tPROFESSION: precision:  86.18%; recall:  91.14%; F1:  88.59 2851\n",
      "\n",
      "\tRELIGION: precision:  0.00%; recall:  0.00%; F1:  0.00 0\n",
      "\n",
      "\tSTATE_OR_PROVINCE: precision:  54.94%; recall:  59.81%; F1:  57.27 344\n",
      "\n",
      "\tTIME: precision:  46.55%; recall:  31.40%; F1:  37.50 58\n",
      "\n",
      "\tWORK_OF_ART: precision:  38.75%; recall:  19.87%; F1:  26.27 80\n",
      "\n",
      "\n",
      "Eval on valid:\n",
      "processed 11830 tokens with 2535 phrases; found: 2148 phrases; correct: 1208.\n",
      "\n",
      "precision:  56.24%; recall:  47.65%; FB1:  51.59\n",
      "\n",
      "\tAGE: precision:  85.14%; recall:  88.73%; F1:  86.90 74\n",
      "\n",
      "\tAWARD: precision:  0.00%; recall:  0.00%; F1:  0.00 2\n",
      "\n",
      "\tCITY: precision:  71.59%; recall:  44.68%; F1:  55.02 88\n",
      "\n",
      "\tCOUNTRY: precision:  84.88%; recall:  76.65%; F1:  80.56 205\n",
      "\n",
      "\tCRIME: precision:  33.33%; recall:  11.76%; F1:  17.39 6\n",
      "\n",
      "\tDATE: precision:  74.52%; recall:  74.81%; F1:  74.67 263\n",
      "\n",
      "\tDISEASE: precision:  0.00%; recall:  0.00%; F1:  0.00 0\n",
      "\n",
      "\tDISTRICT: precision:  0.00%; recall:  0.00%; F1:  0.00 0\n",
      "\n",
      "\tEVENT: precision:  45.00%; recall:  39.60%; F1:  42.13 220\n",
      "\n",
      "\tFACILITY: precision:  0.00%; recall:  0.00%; F1:  0.00 7\n",
      "\n",
      "\tFAMILY: precision:  0.00%; recall:  0.00%; F1:  0.00 0\n",
      "\n",
      "\tIDEOLOGY: precision:  66.67%; recall:  17.39%; F1:  27.59 6\n",
      "\n",
      "\tLANGUAGE: precision:  0.00%; recall:  0.00%; F1:  0.00 0\n",
      "\n",
      "\tLAW: precision:  100.00%; recall:  6.67%; F1:  12.50 1\n",
      "\n",
      "\tLOCATION: precision:  0.00%; recall:  0.00%; F1:  0.00 1\n",
      "\n",
      "\tMONEY: precision:  71.43%; recall:  66.67%; F1:  68.97 28\n",
      "\n",
      "\tNATIONALITY: precision:  32.14%; recall:  18.00%; F1:  23.08 28\n",
      "\n",
      "\tNUMBER: precision:  61.18%; recall:  57.14%; F1:  59.09 85\n",
      "\n",
      "\tORDINAL: precision:  50.00%; recall:  58.70%; F1:  54.00 54\n",
      "\n",
      "\tORGANIZATION: precision:  30.96%; recall:  40.32%; F1:  35.03 323\n",
      "\n",
      "\tPENALTY: precision:  0.00%; recall:  0.00%; F1:  0.00 0\n",
      "\n",
      "\tPERCENT: precision:  0.00%; recall:  0.00%; F1:  0.00 1\n",
      "\n",
      "\tPERSON: precision:  57.38%; recall:  39.02%; F1:  46.45 359\n",
      "\n",
      "\tPRODUCT: precision:  0.00%; recall:  0.00%; F1:  0.00 0\n",
      "\n",
      "\tPROFESSION: precision:  47.96%; recall:  54.15%; F1:  50.87 367\n",
      "\n",
      "\tRELIGION: precision:  0.00%; recall:  0.00%; F1:  0.00 0\n",
      "\n",
      "\tSTATE_OR_PROVINCE: precision:  55.17%; recall:  29.09%; F1:  38.10 29\n",
      "\n",
      "\tTIME: precision:  0.00%; recall:  0.00%; F1:  0.00 1\n",
      "\n",
      "\tWORK_OF_ART: precision:  0.00%; recall:  0.00%; F1:  0.00 0\n",
      "\n",
      "\n",
      "Eval on test:\n",
      "processed 10565 tokens with 2390 phrases; found: 2048 phrases; correct: 1212.\n",
      "\n",
      "precision:  59.18%; recall:  50.71%; FB1:  54.62\n",
      "\n",
      "\tAGE: precision:  77.78%; recall:  86.15%; F1:  81.75 72\n",
      "\n",
      "\tAWARD: precision:  0.00%; recall:  0.00%; F1:  0.00 1\n",
      "\n",
      "\tCITY: precision:  56.73%; recall:  47.20%; F1:  51.53 104\n",
      "\n",
      "\tCOUNTRY: precision:  85.04%; recall:  73.98%; F1:  79.13 234\n",
      "\n",
      "\tCRIME: precision:  50.00%; recall:  11.11%; F1:  18.18 2\n",
      "\n",
      "\tDATE: precision:  73.96%; recall:  75.38%; F1:  74.67 265\n",
      "\n",
      "\tDISEASE: precision:  0.00%; recall:  0.00%; F1:  0.00 0\n",
      "\n",
      "\tDISTRICT: precision:  0.00%; recall:  0.00%; F1:  0.00 0\n",
      "\n",
      "\tEVENT: precision:  42.57%; recall:  36.13%; F1:  39.09 202\n",
      "\n",
      "\tFACILITY: precision:  0.00%; recall:  0.00%; F1:  0.00 5\n",
      "\n",
      "\tIDEOLOGY: precision:  50.00%; recall:  6.67%; F1:  11.76 2\n",
      "\n",
      "\tLANGUAGE: precision:  0.00%; recall:  0.00%; F1:  0.00 0\n",
      "\n",
      "\tLAW: precision:  0.00%; recall:  0.00%; F1:  0.00 1\n",
      "\n",
      "\tLOCATION: precision:  100.00%; recall:  4.35%; F1:  8.33 1\n",
      "\n",
      "\tMONEY: precision:  44.44%; recall:  100.00%; F1:  61.54 9\n",
      "\n",
      "\tNATIONALITY: precision:  31.03%; recall:  20.93%; F1:  25.00 29\n",
      "\n",
      "\tNUMBER: precision:  60.71%; recall:  68.00%; F1:  64.15 112\n",
      "\n",
      "\tORDINAL: precision:  75.38%; recall:  61.25%; F1:  67.59 65\n",
      "\n",
      "\tORGANIZATION: precision:  39.13%; recall:  45.19%; F1:  41.94 276\n",
      "\n",
      "\tPENALTY: precision:  0.00%; recall:  0.00%; F1:  0.00 0\n",
      "\n",
      "\tPERCENT: precision:  0.00%; recall:  0.00%; F1:  0.00 0\n",
      "\n",
      "\tPERSON: precision:  70.31%; recall:  47.58%; F1:  56.75 293\n",
      "\n",
      "\tPRODUCT: precision:  0.00%; recall:  0.00%; F1:  0.00 0\n",
      "\n",
      "\tPROFESSION: precision:  47.49%; recall:  60.07%; F1:  53.05 339\n",
      "\n",
      "\tRELIGION: precision:  0.00%; recall:  0.00%; F1:  0.00 0\n",
      "\n",
      "\tSTATE_OR_PROVINCE: precision:  30.43%; recall:  17.50%; F1:  22.22 23\n",
      "\n",
      "\tTIME: precision:  0.00%; recall:  0.00%; F1:  0.00 4\n",
      "\n",
      "\tWORK_OF_ART: precision:  11.11%; recall:  3.57%; F1:  5.41 9\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from ner.network import NER\n",
    "import tensorflow as tf\n",
    "\n",
    "learning_params = {'dropout_rate': 0.5,\n",
    "                'epochs': 15,\n",
    "                'learning_rate': 0.005,\n",
    "                'batch_size': 8,\n",
    "                'learning_rate_decay': 0.707}\n",
    "\n",
    "model_params = {\"filter_width\": 7,\n",
    "            \"embeddings_dropout\": True,\n",
    "            \"n_filters\": [\n",
    "                128, 128,\n",
    "            ],\n",
    "            \"token_embeddings_dim\": 100,\n",
    "            \"char_embeddings_dim\": 25,\n",
    "            \"use_batch_norm\": True,\n",
    "            \"use_crf\": True,\n",
    "            \"net_type\": 'cnn',\n",
    "            \"use_capitalization\": True,\n",
    "            }\n",
    "\n",
    "net = NER(corp, **model_params) # initialise the model\n",
    "results = net.fit(**learning_params) # train the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_back(tokens, tags):\n",
    "    \"\"\"\n",
    "    convert tokens and tags back to a sentence and a list of entities\n",
    "    \"\"\"\n",
    "    sentence = \"\"\n",
    "    entities = []\n",
    "    current_entity = None\n",
    "    start_index = 0\n",
    "    for token, tag in zip(tokens, tags):\n",
    "        if tag.startswith(\"B-\"):  # If this is the beginning of the entity\n",
    "            if current_entity is not None:  # if there is an entity in progress\n",
    "                entities.append([start_index, len(sentence.strip()), current_entity])\n",
    "            current_entity = tag[2:]\n",
    "            sentence += \" \" + token\n",
    "            start_index = len(sentence.strip()) - len(token)\n",
    "        elif tag.startswith(\"I-\"):  # if this is the intermediate part of the entity\n",
    "            if current_entity is not None:  # if there is an entity in progress\n",
    "                sentence += \" \" + token\n",
    "        else:  # if this is not an entity\n",
    "            if current_entity is not None:  # if there is an entity in progress\n",
    "                entities.append([start_index, len(sentence.strip()), current_entity])\n",
    "                current_entity = None\n",
    "            sentence += \" \" + token\n",
    "    if current_entity is not None:  # if there is an entity in progress at the end of the sentence\n",
    "        entities.append([start_index, len(sentence.strip()), current_entity])\n",
    "    return entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 65/65 [00:05<00:00, 10.93it/s]\n"
     ]
    }
   ],
   "source": [
    "from ner.utils import tokenize, lemmatize\n",
    "\n",
    "def save_to_jsonl(filename, data): # save the data to a JSONL file\n",
    "    with open(filename, 'w', encoding='utf-8') as f:\n",
    "        for entities in data:\n",
    "            json_line = {\"ners\": entities}\n",
    "            f.write(json.dumps(json_line, ensure_ascii=False) + '\\n')\n",
    "\n",
    "def predict(sentence, network):\n",
    "    # split sentence into tokens\n",
    "    tokens = tokenize(sentence)\n",
    "    # lemmatize tokens\n",
    "    tokens_lemmas = lemmatize(tokens)\n",
    "    # predict tags\n",
    "    tags = network.predict_for_token_batch([tokens_lemmas])[0]\n",
    "    return tokens, tags\n",
    "\n",
    "output = []\n",
    "for sentence in tqdm(dev_data):\n",
    "    tokens, tags = predict(sentence[\"senences\"], net) # predict tags for the sentence\n",
    "    output.append(convert_back(tokens, tags)) # convert tokens and tags back to entities\n",
    "\n",
    "save_to_jsonl(\"test.jsonl\", output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
